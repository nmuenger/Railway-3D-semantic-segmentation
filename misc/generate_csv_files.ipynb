{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import raillabel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebooks create the .csv files \"person_frames.csv\", and \"pedestrian_density_per_distance.csv\", required for the Person Instances Pasting augmentation. <br>\n",
    "**person_frames.csv** defines for each train set's frmae, whether it contains a person instance or not. <br>\n",
    "**pedestrian_density_per_distance.csv** contains for each person instance, the distance from origin, the number of points constituing the instance, the average intensity, and the scene/frame characteristic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'person_frames.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strings to add\n",
    "suffixes = ['_nb_points', '_nb_annotations']\n",
    "\n",
    "class_labels= ['person', 'crowd','train','wagons','bicycle','group_of_bicycles','motorcycle','road_vehicle',\n",
    "'animal','group_of_animals','wheelchair','drag_shoe', 'track','transition', 'switch','catenary_pole',\n",
    "'signal_pole', 'signal', 'signal_bridge', 'buffer_stop', 'flame', 'smoke']\n",
    "\n",
    "OSDaR_path = \"data/OSDaR23_dataset\"\n",
    "\n",
    "# Initialize the new list\n",
    "df_column_names = []\n",
    "\n",
    "# Iterate through each element in the original list\n",
    "for item in class_labels:\n",
    "    # Append the original element with each suffix\n",
    "    for suffix in suffixes:\n",
    "        df_column_names.append(item + suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=df_column_names)\n",
    "train_set = [\"1_calibration_1.2\",\"3_fire_site_3.1\",\"3_fire_site_3.3\",\"4_station_pedestrian_bridge_4.3\",\"5_station_bergedorf_5.1\",\"6_station_klein_flottbek_6.2\",\"8_station_altona_8.1\",\"8_station_altona_8.2\",\"9_station_ruebenkamp_9.1\",\"12_vegetation_steady_12.1\",\"14_signals_station_14.1\",\"15_construction_vehicle_15.1\",\"20_vegetation_squirrel_20.1\",\"21_station_wedel_21.1\",\"21_station_wedel_21.2\"]\n",
    "\n",
    "person_scene_list = []\n",
    "person_frame_list = []\n",
    "person_bool = []\n",
    "\n",
    "\n",
    "for folder_name in train_set: # Iterate through each scene\n",
    "    folder_path = os.path.join(OSDaR_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path): \n",
    "        json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "\n",
    "        if len(json_files) > 1:\n",
    "            print('More than one json file was found for scene:', folder_name, 'which is unexpected behaviour. Exiting loop')\n",
    "            break\n",
    "        else:\n",
    "            print(json_files)\n",
    "            json_file_path = os.path.join(folder_path, json_files[0])\n",
    "            scene = raillabel.load(json_file_path)\n",
    "\n",
    "            person_filtered = raillabel.filter(scene, include_annotation_types=['seg3d'], include_object_types=[\"person\"])\n",
    "            \n",
    "            \n",
    "            for frame in person_filtered.frames.keys():\n",
    "                person_scene_list.append(folder_name)\n",
    "                person_frame_list.append(frame)\n",
    "                if len(person_filtered.frames[frame].annotations)>=1:\n",
    "                    person_bool.append(True)\n",
    "                else:\n",
    "                    person_bool.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"scene\":person_scene_list, \"frame\":person_frame_list, \"presence\":person_bool})\n",
    "\n",
    "df['frame'] = df['frame'].astype(str).str.zfill(3)\n",
    "\n",
    "person_filtered_frames = df[df[\"presence\"]==True]\n",
    "\n",
    "person_filtered_frames.to_csv(\"/workspaces/baseline/exp/person_frames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'pedestrian_density_per_distance.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[\"1_calibration_1.2\",\"3_fire_site_3.1\",\"3_fire_site_3.3\",\"4_station_pedestrian_bridge_4.3\",\"5_station_bergedorf_5.1\",\"6_station_klein_flottbek_6.2\",\"8_station_altona_8.1\",\"8_station_altona_8.2\",\"9_station_ruebenkamp_9.1\",\"12_vegetation_steady_12.1\",\"14_signals_station_14.1\",\"15_construction_vehicle_15.1\",\"20_vegetation_squirrel_20.1\",\"21_station_wedel_21.1\",\"21_station_wedel_21.2\"]\n",
    "val=[\"2_station_berliner_tor_2.1\",\"3_fire_site_3.4\",\"4_station_pedestrian_bridge_4.2\",\"4_station_pedestrian_bridge_4.5\",\"6_station_klein_flottbek_6.1\",\"7_approach_underground_station_7.2\",\"9_station_ruebenkamp_9.3\",\"9_station_ruebenkamp_9.4\",\"9_station_ruebenkamp_9.5\",\"9_station_ruebenkamp_9.7\",\"11_main_station_11.1\",\"14_signals_station_14.2\",\"14_signals_station_14.3\",\"18_vegetation_switch_18.1\",\"21_station_wedel_21.3\"]\n",
    "test=[\"1_calibration_1.1\",\"3_fire_site_3.2\",\"4_station_pedestrian_bridge_4.1\",\"4_station_pedestrian_bridge_4.4\",\"5_station_bergedorf_5.2\",\"7_approach_underground_station_7.1\",\"7_approach_underground_station_7.3\",\"8_station_altona_8.3\",\"9_station_ruebenkamp_9.2\",\"9_station_ruebenkamp_9.6\",\"10_station_suelldorf_10.1\",\"13_station_ohlsdorf_13.1\",\"16_under_bridge_16.1\",\"17_signal_bridge_17.1\",\"19_vegetation_curve_19.1\"]\n",
    "\n",
    "\n",
    "# Uncomment block below to reprocess the dataframe\n",
    "person_instance_distance = []\n",
    "person_instance_nb_points = []\n",
    "person_instance_mean_intensity = []\n",
    "scenes_name_list = []\n",
    "\n",
    "scene_progress=0\n",
    "for folder_scene_name in os.listdir(OSDaR_path): # Iterate through each scene\n",
    "    print(\"Scene progress =\", scene_progress, \". Scene name:\",folder_scene_name)\n",
    "    folder_scene_path = os.path.join(OSDaR_path, folder_scene_name)\n",
    "    lidar_folder_scene_path = os.path.join(folder_scene_path,\"lidar\")\n",
    "\n",
    "    scene_name = os.path.basename(os.path.normpath(folder_scene_path))\n",
    "\n",
    "    if scene_name not in train+val+test:\n",
    "        #The file should be there, skip\n",
    "        continue\n",
    "\n",
    "    scene_number = float(scene_name.rsplit(\"_\",1)[1])\n",
    "\n",
    "    label_scene_path = os.path.join(folder_scene_path, scene_name+\"_labels.json\")\n",
    "\n",
    "    if os.path.exists(label_scene_path):\n",
    "        scene = raillabel.load(label_scene_path) # Load json annotations for scene\n",
    "\n",
    "    for lidar_frame_name in os.listdir(lidar_folder_scene_path):\n",
    "        lidar_frame_path = os.path.join(lidar_folder_scene_path,lidar_frame_name)\n",
    "        # Returns the frame number as int '037'-> 37 \n",
    "        frame_nb = int(lidar_frame_name.split('_')[0])\n",
    "\n",
    "        scene_filtered = raillabel.filter(scene, include_frames=[frame_nb], include_annotation_types=['seg3d'], include_object_types=[\"person\"])\n",
    "\n",
    "        if frame_nb not in scene_filtered.frames: # One of the point cloud doesnt have any frame annotation\n",
    "            print(\"Skipped frame\")\n",
    "            continue\n",
    " \n",
    "        if frame_nb in scene_filtered.frames and len(scene_filtered.frames[frame_nb].annotations)==0:\n",
    "            print(\"No pededestrian in that frame, skip\")\n",
    "            continue # There are not person annotation in this pcd, skip\n",
    "\n",
    "        with open(lidar_frame_path, \"r\") as pcd:\n",
    "            scan = np.loadtxt(pcd, skiprows=11, usecols=(0,1,2,3))\n",
    "        coord = scan[:, :3]     # The x,y,z coordinates of the points \n",
    "        strength = scan[:, -1].reshape([-1, 1]) # The intensity of the points \n",
    "        point_distances = np.linalg.norm(coord[:,:2],axis=1)\n",
    "        # If point has no particular label, it is background\n",
    "        point_labels = np.full(len(scan), 0)\n",
    "\n",
    "        if frame_nb in scene_filtered.frames: # One of the point cloud doesnt have any frame annotation\n",
    "            frame_objects = scene_filtered.frames[frame_nb].annotations.keys()\n",
    "            \n",
    "            for object in frame_objects:  \n",
    "                pts_idx = scene_filtered.frames[frame_nb].annotations[object].point_ids # Points index for the object\n",
    "                instance_coords = coord[pts_idx]\n",
    "                x_min, y_min= instance_coords[:,0:2].min(axis=0)\n",
    "                x_max, y_max= instance_coords[:,0:2].max(axis=0)\n",
    "                center_x = x_min+(x_max-x_min)/2\n",
    "                center_y = y_min+(y_max-y_min)/2\n",
    "                center_distance = np.linalg.norm([center_x, center_y])\n",
    "\n",
    "                person_instance_distance.append(center_distance)\n",
    "                person_instance_nb_points.append(len(pts_idx))\n",
    "                person_instance_mean_intensity.append(strength[pts_idx].mean())\n",
    "                scenes_name_list.append(scene_name)\n",
    "\n",
    "        else:\n",
    "            pass # Keep all points of the point cloud as ignore_index\n",
    "        \n",
    "    scene_progress += 1\n",
    "\n",
    "split_df = pd.DataFrame({\"scene_name\": train+val+test,\n",
    "                         \"split\": [\"train\"]*len(train)+[\"val\"]*len(val)+[\"test\"]*len(test)})\n",
    "\n",
    "pedestrian_df = pd.DataFrame({\"dist\":person_instance_distance, \n",
    "                                \"nb_points\":person_instance_nb_points, \n",
    "                                \"mean_intensity\":person_instance_mean_intensity,\n",
    "                                \"scene_name\": scenes_name_list})\n",
    "\n",
    "pedestrian_df = pedestrian_df.merge(split_df, how=\"left\", on=\"scene_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save CSV\n",
    "pedestrian_df.to_csv(\"/workspaces/baseline/exp/csv_stats/pedestrian_density_per_distance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
